{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_t = torch.normal(2*torch.ones(100,2),1)\n",
    "y1_t = torch.zeros(100)\n",
    "\n",
    "x2_t = torch.normal(-2*torch.ones(100,2),1)\n",
    "y2_t = torch.ones(100)\n",
    "\n",
    "x_t = torch.cat((x1_t,x2_t),0)\n",
    "y_t = torch.cat((y1_t,y2_t),0)\n",
    "\n",
    "dataloader = DataLoader(TensorDataset(x_t, y_t), batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(2,5),  # 输入层与第一隐层结点数设置，全连接结构\n",
    "    torch.nn.Sigmoid(),  # 第一隐层激活函数采用sigmoid\n",
    "    nn.Linear(5,5),  # 第一隐层与第二隐层结点数设置，全连接结构\n",
    "    torch.nn.Sigmoid(),  # 第一隐层激活函数采用sigmoid\n",
    "    nn.Linear(5,2),  # 第二隐层与输出层层结点数设置，全连接结构\n",
    "    nn.Softmax(dim=1) # 由于有两个概率输出，因此对其使用Softmax进行概率归一化\n",
    ")\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.01) # 优化器使用随机梯度下降，传入网络参数和学习率\n",
    "loss_func = torch.nn.CrossEntropyLoss() # 损失函数使用交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "batch: 0, loss: 0.7121411561965942\n",
      "batch: 1, loss: 0.7094587087631226\n",
      "batch: 2, loss: 0.7102700471878052\n",
      "batch: 3, loss: 0.6641179323196411\n",
      "batch: 4, loss: 0.6957534551620483\n",
      "batch: 5, loss: 0.695778489112854\n",
      "batch: 6, loss: 0.7108780145645142\n",
      "batch: 7, loss: 0.6649313569068909\n",
      "batch: 8, loss: 0.6782379746437073\n",
      "batch: 9, loss: 0.6950819492340088\n",
      "batch: 10, loss: 0.6807325482368469\n",
      "batch: 11, loss: 0.6950427293777466\n",
      "batch: 12, loss: 0.712128758430481\n",
      "batch: 13, loss: 0.7396572232246399\n",
      "batch: 14, loss: 0.7260257005691528\n",
      "batch: 15, loss: 0.6190959215164185\n",
      "batch: 16, loss: 0.6785600781440735\n",
      "batch: 17, loss: 0.7127264738082886\n",
      "batch: 18, loss: 0.6801777482032776\n",
      "batch: 19, loss: 0.7244067788124084\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))\n",
    "for batch, (x, y) in enumerate(dataloader):\n",
    "    y_p = net(x)\n",
    "    loss = loss_func(y_p, y.long())\n",
    "    print(f'batch: {batch}, loss: {loss}')\n",
    "    # print(f'batch: {batch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb121e15e5893a7aefeb2f86e51d80a90a82f7b1cae21a906a81a78834249b4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
